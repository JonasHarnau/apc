{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log-Normal or Over-Dispersed Poisson?\n",
    "\n",
    "We replicate the empirical applications in [Harnau (2018a)](http://www.mdpi.com/2227-9091/6/3/70) in Section 2 and Section 6.\n",
    "\n",
    "*The work on this vignette was supported by the European Research Council, grant AdG 694262.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off FutureWarnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Empirical illustration of the problem\n",
    "\n",
    "This section motivates the problem. Based on the Verrall et al. (2010) it applies the misspecification tests from [Harnau (2018b)](http://www.mdpi.com/2227-9091/6/2/25). We split the data into two sub-samples after the fifth accident year. Then we test for breaks in dispersion parameters with a Bartlett test and linear predictors with an F-test.\n",
    "\n",
    "*Remark: we replicated the empirical applications in Harnau (2018b) [here](https://github.com/JonasHarnau/apc/blob/master/apc/vignettes/vignette_misspecification.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_normal_response\n",
      "===================\n",
      "Bartlett test p-value: 0.09\n",
      "F-test p-value: 0.91 \n",
      "\n",
      "od_poisson_response\n",
      "===================\n",
      "Bartlett test p-value: 0.78\n",
      "F-test p-value: 0.64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for family in ('log_normal_response', 'od_poisson_response'):\n",
    "    model_VNJ = apc.Model()\n",
    "    model_VNJ.data_from_df(apc.loss_VNJ(), data_format='CL')\n",
    "    model_VNJ.fit(family, 'AC')\n",
    "    \n",
    "    sub_models_VNJ = [model_VNJ.sub_model(coh_from_to=(1,5)),\n",
    "                     model_VNJ.sub_model(coh_from_to=(6,10))]\n",
    "\n",
    "    bartlett_VNJ = apc.bartlett_test(sub_models_VNJ)\n",
    "    f_VNJ = apc.f_test(model_VNJ, sub_models_VNJ)\n",
    "    \n",
    "    print(family)\n",
    "    print('='*len(family))\n",
    "    print('Bartlett test p-value: {:.2f}'.format(\n",
    "        bartlett_VNJ['p_value']))\n",
    "    print('F-test p-value: {:.2f} \\n'.format(\n",
    "        f_VNJ['p_value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither in a log-normal nor in an over-dispersed Poisson model can we convincingly reject the model specification based on these tests. This illustrates a situation in which it is not clear what model to use so that the new R-test can prove its usefulness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Empirical illustration revisited\n",
    "\n",
    "In this section, we return to the empirical illustration from above and test whether an R-test can help us to decide between (generalized) log-normal and over-dispersed Poisson model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package comes with built-in functionality for the R-test. Say we want to test \n",
    "$$ H_0: \\text{generalized log-normal} \\quad \\text{vs} \\quad \\text{over-dispersed Poisson} $$\n",
    "based on the statistic $R^*_{ls}$ and compare it to $\\widehat{\\mathrm{R}}^*_{ls}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred 'data_format' from response: CA\n",
      "R-statistic: 113.19\n",
      "p_value: 0.0011\n"
     ]
    }
   ],
   "source": [
    "r_VNJ = apc.r_test(apc.loss_VNJ(), # specify the data set\n",
    "                   family_null='gen_log_normal_response', # declare null model\n",
    "                   predictor='AC', # AC = age-cohort matching the chain-ladder\n",
    "                   R_stat='wls_ls', # R-stat: wls_ls -> R^{star}_{ls}\n",
    "                   R_dist='wls_ls') # Pi est in limiting dist: wls_ls -> Pi^{star}_{ls}\n",
    "print('R-statistic: {:.2f}'.format(r_VNJ['R_stat']))\n",
    "print('p_value: {:.4f}'.format(r_VNJ['p_value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matches the value for the statistic in the paper and the p-value in Table 3 (which is given in %).\n",
    "\n",
    "*Remark: besides the value of the test statistic and the p-value under the null, apc.r_test also return the power at the value oder the R-statistic (*```power_at_R```*). The power corresponds to one minus the p-value under the alternative.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To replicate the remaining test statistics and the entire Table 3 we employ a small function that iterates over all possible combinations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def r_test_all_combs(model):\n",
    "    # create an empty series to be filled with R-statistics\n",
    "    R_stats = pd.Series(None, index=('$R_{ls}$', '$R_{ql}$', \n",
    "                                     '$R^*_{ls}$', '$R^*_{ql}$'))\n",
    "    # create and empty df to be filled with p-values\n",
    "    base_df = pd.DataFrame(\n",
    "        None, \n",
    "        index = ('$\\widehat{\\mathrm{R}}_{ls}$', \n",
    "                 '$\\widehat{\\mathrm{R}}_{ql}$', \n",
    "                 '$\\widehat{\\mathrm{R}}^*_{ls}$', \n",
    "                 '$\\widehat{\\mathrm{R}}^*_{ql}$'),\n",
    "        columns = pd.MultiIndex.from_product(\n",
    "            [\n",
    "                ('$H_0: $ generalized log-normal', \n",
    "                 '$H_0: $ over-dispersed Poisson'),\n",
    "                ('$R_{ls}$', '$R_{ql}$', '$R^*_{ls}$', '$R^*_{ql}$')\n",
    "            ])\n",
    "    )\n",
    "    # iterate over ways to compute the R-statistic\n",
    "    for i, R_stat in enumerate(['ls', 'ql', 'wls_ls', 'wls_ql']):\n",
    "        # iterate over ways to estimate Pi in the limiting dist\n",
    "        for j, R_dist in enumerate(['ls', 'ql', 'wls_ls', 'wls_ql']):\n",
    "            # compute R-test\n",
    "            r_test = apc.r_test(apc.loss_VNJ(), \n",
    "                                family_null='gen_log_normal_response',\n",
    "                                predictor='AC', \n",
    "                                R_stat=R_stat, R_dist=R_dist, \n",
    "                                data_format='CL')\n",
    "            base_df.iloc[j, i] = r_test['p_value']\n",
    "            base_df.iloc[j, i+4] = 1 - r_test['power_at_R']\n",
    "        R_stats.iloc[i] = r_test['R_stat']\n",
    "    return base_df, R_stats\n",
    "\n",
    "table3, R_stats = r_test_all_combs(model_VNJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-statistics are as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$R_{ls}$</th>\n",
       "      <th>$R_{ql}$</th>\n",
       "      <th>$R^*_{ls}$</th>\n",
       "      <th>$R^*_{ql}$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R-Statistic</th>\n",
       "      <td>104.869134</td>\n",
       "      <td>105.610958</td>\n",
       "      <td>113.185124</td>\n",
       "      <td>108.39224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               $R_{ls}$    $R_{ql}$  $R^*_{ls}$  $R^*_{ql}$\n",
       "R-Statistic  104.869134  105.610958  113.185124   108.39224"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(R_stats.rename('R-Statistic')).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And Table 3 is given by this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">$H_0: $ generalized log-normal</th>\n",
       "      <th colspan=\"4\" halign=\"left\">$H_0: $ over-dispersed Poisson</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>$R_{ls}$</th>\n",
       "      <th>$R_{ql}$</th>\n",
       "      <th>$R^*_{ls}$</th>\n",
       "      <th>$R^*_{ql}$</th>\n",
       "      <th>$R_{ls}$</th>\n",
       "      <th>$R_{ql}$</th>\n",
       "      <th>$R^*_{ls}$</th>\n",
       "      <th>$R^*_{ql}$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$\\widehat{\\mathrm{R}}_{ls}$</th>\n",
       "      <td>0.425208</td>\n",
       "      <td>0.385867</td>\n",
       "      <td>0.142406</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>8.53354</td>\n",
       "      <td>9.00184</td>\n",
       "      <td>14.5894</td>\n",
       "      <td>10.8861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\widehat{\\mathrm{R}}_{ql}$</th>\n",
       "      <td>0.316337</td>\n",
       "      <td>0.285603</td>\n",
       "      <td>0.100103</td>\n",
       "      <td>0.194504</td>\n",
       "      <td>11.8047</td>\n",
       "      <td>12.4049</td>\n",
       "      <td>19.3502</td>\n",
       "      <td>14.7893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\widehat{\\mathrm{R}}^*_{ls}$</th>\n",
       "      <td>0.351596</td>\n",
       "      <td>0.318049</td>\n",
       "      <td>0.113691</td>\n",
       "      <td>0.218175</td>\n",
       "      <td>10.4221</td>\n",
       "      <td>10.9669</td>\n",
       "      <td>17.3429</td>\n",
       "      <td>13.1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\widehat{\\mathrm{R}}^*_{ql}$</th>\n",
       "      <td>0.38044</td>\n",
       "      <td>0.34464</td>\n",
       "      <td>0.125013</td>\n",
       "      <td>0.237697</td>\n",
       "      <td>9.48055</td>\n",
       "      <td>9.98668</td>\n",
       "      <td>15.9619</td>\n",
       "      <td>12.0142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              $H_0: $ generalized log-normal            \\\n",
       "                                                    $R_{ls}$  $R_{ql}$   \n",
       "$\\widehat{\\mathrm{R}}_{ls}$                         0.425208  0.385867   \n",
       "$\\widehat{\\mathrm{R}}_{ql}$                         0.316337  0.285603   \n",
       "$\\widehat{\\mathrm{R}}^*_{ls}$                       0.351596  0.318049   \n",
       "$\\widehat{\\mathrm{R}}^*_{ql}$                        0.38044   0.34464   \n",
       "\n",
       "                                                     \\\n",
       "                              $R^*_{ls}$ $R^*_{ql}$   \n",
       "$\\widehat{\\mathrm{R}}_{ls}$     0.142406   0.267857   \n",
       "$\\widehat{\\mathrm{R}}_{ql}$     0.100103   0.194504   \n",
       "$\\widehat{\\mathrm{R}}^*_{ls}$   0.113691   0.218175   \n",
       "$\\widehat{\\mathrm{R}}^*_{ql}$   0.125013   0.237697   \n",
       "\n",
       "                              $H_0: $ over-dispersed Poisson           \\\n",
       "                                                    $R_{ls}$ $R_{ql}$   \n",
       "$\\widehat{\\mathrm{R}}_{ls}$                          8.53354  9.00184   \n",
       "$\\widehat{\\mathrm{R}}_{ql}$                          11.8047  12.4049   \n",
       "$\\widehat{\\mathrm{R}}^*_{ls}$                        10.4221  10.9669   \n",
       "$\\widehat{\\mathrm{R}}^*_{ql}$                        9.48055  9.98668   \n",
       "\n",
       "                                                     \n",
       "                              $R^*_{ls}$ $R^*_{ql}$  \n",
       "$\\widehat{\\mathrm{R}}_{ls}$      14.5894    10.8861  \n",
       "$\\widehat{\\mathrm{R}}_{ql}$      19.3502    14.7893  \n",
       "$\\widehat{\\mathrm{R}}^*_{ls}$    17.3429    13.1413  \n",
       "$\\widehat{\\mathrm{R}}^*_{ql}$    15.9619    12.0142  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table3*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper we now move on to find the 5% critical value under the over-dispersed Poisson model as well as the power at that value. This functionality is not directly implemented in the package; however we can easily replicate it with the package [quad_form_ratio](https://github.com/JonasHarnau/quad_form_ratio). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5% critical value for over-dispersed Poisson: 95.7\n",
      "Power at 5% critical value: 0.99\n"
     ]
    }
   ],
   "source": [
    "from quad_form_ratio import saddlepoint_cdf_R, saddlepoint_inv_cdf_R\n",
    "import numpy as np\n",
    "\n",
    "model_VNJ.fit('log_normal_response', 'AC')\n",
    "X, Z = model_VNJ.design, np.log(model_VNJ.data_vector['response'])\n",
    "tau_ls = model_VNJ.fitted_values.sum() \n",
    "sqrt_Pi_ls = np.diag(np.sqrt(model_VNJ.fitted_values/tau_ls))\n",
    "RSS = model_VNJ.RSS\n",
    "\n",
    "X_star_ls, Z_star_ls = sqrt_Pi_ls.dot(X), sqrt_Pi_ls.dot(Z) \n",
    "\n",
    "# fit the weighted least squares model, we set rcond=0. since\n",
    "# we know that X_star has full column rank.\n",
    "wls_ls_fit = np.linalg.lstsq(X_star_ls, Z_star_ls, rcond=0.)\n",
    "xi_star_ls, RSS_star_ls = wls_ls_fit[0], wls_ls_fit[1][0]\n",
    "\n",
    "fitted_wls_ls = np.exp(X.dot(xi_star_ls))\n",
    "sqrt_Pi_star_ls = np.diag(np.sqrt(fitted_wls_ls/fitted_wls_ls.sum()))\n",
    "\n",
    "# Use the QR-decomposition to compute the orthogonal projection M\n",
    "Q, _ = np.linalg.qr(X)\n",
    "M = np.identity(model_VNJ.n) - Q.dot(Q.T)\n",
    "\n",
    "# do the same for the weighted least squares orthogonal projection\n",
    "X_star_ls = sqrt_Pi_star_ls.dot(X)        \n",
    "Q_star_ls, _ = np.linalg.qr(X_star_ls)\n",
    "M_star_ls = np.identity(model_VNJ.n) - Q_star_ls.dot(Q_star_ls.T)\n",
    "\n",
    "# A refers to the sandwiched matrix in the numerator\n",
    "# B refers to the sandwiched matrix in the denominator\n",
    "# _gln and _odp refer to the sandwiches under the respective nulls\n",
    "A_gln = M\n",
    "B_gln = sqrt_Pi_star_ls.dot(M_star_ls).dot(sqrt_Pi_star_ls)\n",
    "A_odp = np.linalg.inv(sqrt_Pi_star_ls).dot(M).dot(np.linalg.inv(sqrt_Pi_star_ls))\n",
    "B_odp = M_star_ls\n",
    "\n",
    "# We compute the 5% critical value under ODP (lower quantile)\n",
    "# The function iterates to find the critical value up to a precision of 0.0001\n",
    "cv = saddlepoint_inv_cdf_R(A_odp, B_odp, probabilities=[0.05])\n",
    "print('5% critical value for over-dispersed Poisson: {:.1f}'.format(cv[0.05]))\n",
    "\n",
    "# Given the critical value, we compute the power\n",
    "pwr_at_cv5 = saddlepoint_cdf_R(A_gln, B_gln, cv)\n",
    "print('Power at 5% critical value: {:.2f}'.format(pwr_at_cv5.iloc[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Sensitivity to invalid model reductions\n",
    "\n",
    "In this section, we use the data from Barnett and Zehnwirth (2000, Table 3.5). These data are known to require a calendar effect for modeling. We show that the test results may be misleading when the baseline model is already misspecified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $H_0:$ Generalized log-normal\n",
    "\n",
    "First, we test in a model with calendar effect so the linear predictor is $\\mu_{ij} = \\alpha_i + \\beta_j + \\gamma_k + \\delta$. The first hypothesis we consider is\n",
    "$$ H_0: \\text{extended generalized log-normal} \\quad \\text{vs} \\quad H_A: \\text{extended over-dispersed Poisson}.$$\n",
    "This is easily tested with an $R$-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-statistic: 114.40\n",
      "p_value: 0.02\n"
     ]
    }
   ],
   "source": [
    "r_BZ_GLNe = apc.r_test(\n",
    "    apc.loss_BZ(), family_null='gen_log_normal_response', \n",
    "    predictor='APC', # APC = age-period-cohort, incl. calendar effect\n",
    "    data_format='CL' # optional, the package can infer the data_format\n",
    ") # the default for R_stat and R_dist are our preferrred 'wls_ls'\n",
    "print('R-statistic: {:.2f}'.format(r_BZ_GLNe['R_stat']))\n",
    "print('p_value: {:.2f}'.format(r_BZ_GLNe['p_value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we reject the extended generalized log-normal model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the rejection of the model, we move on to test whether we can drop the calendar effect:\n",
    "$$ H_0: \\text{generalized log-normal} \\quad \\text{vs} \\quad H_A: \\text{extended generalized log-normal}.$$\n",
    "We can do this with a simple $F$-test, both in a log-normal and a generalized log-normal model (Kuang and Nielsen, 2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-2logL</th>\n",
       "      <th>df_resid</th>\n",
       "      <th>LR_vs_APC</th>\n",
       "      <th>df_vs_APC</th>\n",
       "      <th>F_vs_APC</th>\n",
       "      <th>P&gt;F</th>\n",
       "      <th>aic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>-166.967</td>\n",
       "      <td>45</td>\n",
       "      <td>120.492</td>\n",
       "      <td>9</td>\n",
       "      <td>20.8271</td>\n",
       "      <td>9.59281e-12</td>\n",
       "      <td>-124.967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     -2logL df_resid LR_vs_APC df_vs_APC F_vs_APC          P>F      aic\n",
       "AC -166.967       45   120.492         9  20.8271  9.59281e-12 -124.967"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_BZ = apc.Model()\n",
    "model_BZ.data_from_df(apc.loss_BZ(), data_format='CL')\n",
    "model_BZ.fit_table('log_normal_response', attach_to_self=False).loc[\n",
    "    ['AC'],:\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected for the data at hand, we reject this reduction; the calendar effect is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustrative purposes, we nonetheless move on to test \n",
    "$$ H_0: \\text{generalized log-normal} \\quad \\text{vs} \\quad H_A: \\text{over-dispersed Poisson}, $$\n",
    "thus a scenario in which neither model has a calendar effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-statistic: 87.54\n",
      "p_value: 0.10\n"
     ]
    }
   ],
   "source": [
    "r_BZ_GLN = apc.r_test(\n",
    "    apc.loss_BZ(), family_null='gen_log_normal_response', \n",
    "    predictor='AC', data_format='CL'\n",
    ")\n",
    "print('R-statistic: {:.2f}'.format(r_BZ_GLN['R_stat']))\n",
    "print('p_value: {:.2f}'.format(r_BZ_GLN['p_value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps surprisingly, the generalized log-normal model looks better now - we cannot convincingly reject it against the over-dispersed Poisson model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $H_0:$ Over-dispersed Poisson\n",
    "\n",
    "Now we start the other way around and take the over-dispersed Poisson model as a baseline. First, we again include a calendar effect and test\n",
    "$$ H_0: \\text{extended over-dispersed Poisson} \\quad \\text{vs} \\quad H_A: \\text{extended generalized log-normal}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-statistic: 114.40\n",
      "p_value: 0.14\n",
      "Power at R: 0.98\n"
     ]
    }
   ],
   "source": [
    "r_BZ_ODPe = apc.r_test(\n",
    "    apc.loss_BZ(), family_null='od_poisson_response', data_format='CL'\n",
    ") # the default for predictor is APC, thus includes a calendar effect\n",
    "print('R-statistic: {:.2f}'.format(r_BZ_ODPe['R_stat']))\n",
    "print('p_value: {:.2f}'.format(r_BZ_ODPe['p_value']))\n",
    "print('Power at R: {:.2f}'.format(r_BZ_ODPe['power_at_R']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we cannot reject the over-dispersed Poisson model. The power at the value of $R^*_{ls}$ is $0.98$; this corresponds to one minus the p-value under the extended generalized log-normal null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as before, we can test whether we can reasonably drop the calendar effect, just now from the extended over-dispersed Poisson model:\n",
    "$$ H_0: \\text{over-dispersed Poisson} \\quad \\text{vs} \\quad H_A: \\text{extended over-dispersed Poisson}.$$\n",
    "This is easily done with an $F$-test (Harnau and Nielsen 2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deviance</th>\n",
       "      <th>df_resid</th>\n",
       "      <th>P&gt;chi_sq</th>\n",
       "      <th>LR_vs_APC</th>\n",
       "      <th>df_vs_APC</th>\n",
       "      <th>F_vs_APC</th>\n",
       "      <th>P&gt;F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>36593.9</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32146.4</td>\n",
       "      <td>9</td>\n",
       "      <td>28.9124</td>\n",
       "      <td>6.9833e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   deviance df_resid P>chi_sq LR_vs_APC df_vs_APC F_vs_APC         P>F\n",
       "AC  36593.9       45      NaN   32146.4         9  28.9124  6.9833e-14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_BZ = apc.Model()\n",
    "model_BZ.data_from_df(apc.loss_BZ(), data_format='CL')\n",
    "model_BZ.fit_table('od_poisson_response', attach_to_self=False).loc[\n",
    "    ['AC'],:\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One again, this reduction is rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neglecting this result, we investigate what happens if we test the models without calendar effect in\n",
    "$$ H_0: \\text{over-dispersed Poisson} \\quad \\text{vs} \\quad H_A: \\text{generalized log-normal}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-statistic: 87.54\n",
      "p_value: 0.01\n"
     ]
    }
   ],
   "source": [
    "r_BZ_ODP = apc.r_test(\n",
    "    apc.loss_BZ(), family_null='od_poisson_response', \n",
    "    predictor='AC', data_format='CL'\n",
    ")\n",
    "print('R-statistic: {:.2f}'.format(r_BZ_ODP['R_stat']))\n",
    "print('p_value: {:.2f}'.format(r_BZ_ODP['p_value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we reject the over-dispersed Poisson model. Thus, the results completely flipped by dropping the calendar effect. With calendar effect, we cannot reject the over-dispersed Poisson model but can reject the generalized log-normal model. By dropping the much needed calendar effect, we turn this on its head and reject the over-dispersed Poisson but not the generalized log-normal model. Thus, we should be careful what we use as a baseline model before testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 A general to specific testing procedure\n",
    "\n",
    "Taking into account the insights from above, we now consider a general to specific testing procedure. That is, we start with \"the most general\" model and test for possible reductions, stopping once we run into a rejection. For this application, we consider the data by Taylor and Ashe (1983) that has been become a kinda of benchmark data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we consider an extended generalized log-normal model and test it against its over-dispersed Poisson counterpart:\n",
    "$$ H_0: \\text{extended generalized log-normal} \\quad \\text{vs} \\quad H_A: \\text{extended over-dispersed Poisson}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-statistic: 81.54\n",
      "p_value: 0.0012\n"
     ]
    }
   ],
   "source": [
    "r_TA_GLNe = apc.r_test(\n",
    "    apc.loss_TA(), family_null='gen_log_normal_response', \n",
    "    predictor='APC', data_format='CL'\n",
    ")\n",
    "print('R-statistic: {:.2f}'.format(r_TA_GLNe['R_stat']))\n",
    "print('p_value: {:.4f}'.format(r_TA_GLNe['p_value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $R$-test rejects the extended generalized log-normal model. Thus, we do not proceed with this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we now consider the reverse test:\n",
    "$$ H_0: \\text{extended over-dispersed Poisson} \\quad \\text{vs} \\quad H_A: \\text{extended generalized log-normal}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-statistic: 81.54\n",
      "p_value: 0.9238\n",
      "Power at R: 1.00\n"
     ]
    }
   ],
   "source": [
    "r_TA_ODPe = apc.r_test(\n",
    "    apc.loss_TA(), family_null='od_poisson_response', \n",
    "    predictor='APC', data_format='CL'\n",
    ")\n",
    "print('R-statistic: {:.2f}'.format(r_TA_ODPe['R_stat']))\n",
    "print('p_value: {:.4f}'.format(r_TA_ODPe['p_value']))\n",
    "print('Power at R: {:.2f}'.format(r_TA_ODPe['power_at_R']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot reject the hypothesis. Thus, we got to hunt for further evidence against the extended over-dispersed Poisson model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the misspecification tests from Harnau (2018b). In the extended over-dipsersed Poisson model with calendar effect, we split the data into four sub-samples and then test\n",
    "$$ H_{\\sigma^2}: \\sigma^2_\\ell = \\sigma^2 $$\n",
    "with a Bartlett test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bartlett test p-value: 0.05\n"
     ]
    }
   ],
   "source": [
    "model_TAe = apc.Model()\n",
    "model_TAe.data_from_df(apc.loss_TA(), data_format='CL')\n",
    "model_TAe.fit('od_poisson_response', 'APC')\n",
    "\n",
    "sub_models_TAe = [model_TAe.sub_model(per_from_to=(1,5)),\n",
    "                  model_TAe.sub_model(\n",
    "                      coh_from_to=(1,5), age_from_to=(1,5), per_from_to=(6,10)\n",
    "                  ),\n",
    "                  model_TAe.sub_model(age_from_to=(6,10)),\n",
    "                  model_TAe.sub_model(coh_from_to=(6,10))]\n",
    "\n",
    "bartlett_TA_ODPe = apc.bartlett_test(sub_models_TAe)\n",
    "print('Bartlett test p-value: {:.2f}'.format(bartlett_TA_ODPe['p_value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a somewhat close call. In light of the fact that simpler models tend to perform better in forecasting, we interpret the test result as the absence of strong evidence against the hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, taking $H_{\\sigma^2}$ as given, we can move on to test for breaks in linear predictors across sub-samples \n",
    "$$ H_{\\mu, \\sigma^2}: \\alpha_{i, \\ell} + \\beta_{j, \\ell} + \\gamma_{k, \\ell} + \\delta_\\ell = \\alpha_i + \\beta_j + \\gamma_k + \\delta. $$\n",
    "We do so using an $F$-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-test p-value: 0.07 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_TA_ODPe = apc.f_test(model_TAe, sub_models_TAe)\n",
    "print('F-test p-value: {:.2f} \\n'.format(f_TA_ODPe['p_value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to before, we take the result of the $F$-test as a lack of convincing evidence against the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we now consider whether we can reduce the model by dropping the calendar effect by means of an $F$-test for\n",
    "$$ H_0: \\text{over-dispersed Poisson} \\quad \\text{vs} \\quad H_A: \\text{extended over-dispersed Poisson}. $$\n",
    "That is, we consider a reduction from $\\mu_{ij} = \\alpha_i + \\beta_j + \\gamma_k + \\delta$ to $\\mu_{ij} = \\alpha_i + \\beta_j + \\delta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deviance</th>\n",
       "      <th>df_resid</th>\n",
       "      <th>P&gt;chi_sq</th>\n",
       "      <th>LR_vs_APC</th>\n",
       "      <th>df_vs_APC</th>\n",
       "      <th>F_vs_APC</th>\n",
       "      <th>P&gt;F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>1.90301e+06</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>507496</td>\n",
       "      <td>8</td>\n",
       "      <td>1.27281</td>\n",
       "      <td>0.296797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       deviance df_resid P>chi_sq LR_vs_APC df_vs_APC F_vs_APC       P>F\n",
       "AC  1.90301e+06       36      NaN    507496         8  1.27281  0.296797"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_TAe.fit_table(attach_to_self=False).loc[['AC'],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a p-value of $0.30$, we cannot reject this reduction. In the model without calendar effect, point forecasts match the chain-ladder technique forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now consider whether the model without calendar effect still survives the same tests it did before. First, we test it against a generalized log-normal model:\n",
    "$$ H_0: \\text{over-dispersed Poisson} \\quad \\text{vs} \\quad H_A: \\text{generalized log-normal}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-statistic: 73.51\n",
      "p_value: 0.7340\n",
      "Power at R: 1.00\n"
     ]
    }
   ],
   "source": [
    "r_TA_ODP = apc.r_test(\n",
    "    apc.loss_TA(), family_null='od_poisson_response', \n",
    "    predictor='AC', data_format='CL'\n",
    ")\n",
    "print('R-statistic: {:.2f}'.format(r_TA_ODP['R_stat']))\n",
    "print('p_value: {:.4f}'.format(r_TA_ODP['p_value']))\n",
    "print('Power at R: {:.2f}'.format(r_TA_ODP['power_at_R']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model passes this test easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can repeat the misspecification tests, testing\n",
    "$$ H_{\\sigma^2}: \\sigma^2_\\ell = \\sigma^2 $$\n",
    "with a Bartlett test and \n",
    "$$ H_{\\mu, \\sigma^2}: \\alpha_{i, \\ell} + \\beta_{j, \\ell} + \\delta_\\ell = \\alpha_i + \\beta_j + \\delta $$\n",
    "with an $F$-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bartlett test p-value: 0.08\n",
      "F-test p-value: 0.93 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_TA = apc.Model()\n",
    "model_TA.data_from_df(apc.loss_TA(), data_format='CL')\n",
    "model_TA.fit('od_poisson_response', 'AC')\n",
    "\n",
    "sub_models_TA = [model_TA.sub_model(per_from_to=(1,5)),\n",
    "                 model_TA.sub_model(\n",
    "                     coh_from_to=(1,5), age_from_to=(1,5), per_from_to=(6,10)\n",
    "                 ),\n",
    "                 model_TA.sub_model(age_from_to=(6,10)),\n",
    "                 model_TA.sub_model(coh_from_to=(6,10))]\n",
    "\n",
    "bartlett_TA_ODP = apc.bartlett_test(sub_models_TA)\n",
    "f_TA_ODP = apc.f_test(model_TA, sub_models_TA)\n",
    "print('Bartlett test p-value: {:.2f}'.format(bartlett_TA_ODP['p_value']))\n",
    "print('F-test p-value: {:.2f} \\n'.format(f_TA_ODP['p_value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tests pass as well. Thus, we may be somewhat more comfortable in using an over-dispersed Poisson chain-ladder model to generate forecasts for this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* Barnett, G., & Zehnwirth, B. (2000). Best estimates for reserves. *Proceedings of the Casualty Actuarial Society*, 87(167), 245–321.\n",
    "* Harnau, J., & Nielsen, B. (2017). Over-dispersed age-period-cohort models. *Accepted for publication in Journal of the American Statistical Association*. https://doi.org/10.1080/01621459.2017.1366908\n",
    "* Harnau, J. (2018). Log-Normal or Over-Dispersed Poisson? *Risks*, 6(3), 70.\n",
    "* Harnau, J. (2018b). Misspecification Tests for Log-Normal and Over-Dispersed Poisson Chain-Ladder Models. *Risks*, 6(2), 25. \n",
    "* Kuang, D., & Nielsen, B. (2018). Generalized Log-Normal Chain-Ladder. *ArXiv E-Prints 1806.05939*. [Download](http://arxiv.org/abs/1806.05939)\n",
    "* Taylor, G. C., & Ashe, F. R. (1983). Second moments of estimates of outstanding claims. *Journal of Econometrics*, 23(1), 37–61.\n",
    "* Verrall, R., Nielsen, J. P., & Jessen, A. H. (2010). Prediction of RBNS and IBNR claims using claim amounts and claim counts. *ASTIN Bulletin*, 40(2), 871–887."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
